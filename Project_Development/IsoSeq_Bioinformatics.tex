\documentclass[../Main/Knit.tex]{subfiles}
\newpage


\subsection{Bioinformatics Pipeline} 
\label{section:isoseq_bioinformatics}

\begingroup
\parindent=0em
\etocsettocstyle{\rule{\linewidth}{\tocrulewidth}\vskip0.5\baselineskip}{\rule{\linewidth}{\tocrulewidth}}
\etocsetnexttocdepth{5}
\localtableofcontents 
\endgroup

\subsubsection{Introduction}
While the official PacBio bioinformatics tool for processing long Iso-Seq reads has been revised multiple times over the course of this research, the changes have been centred around three main sequeuntial objectives to generate high-quality (HQ) isoforms de novo (Figure X), namely: 
\begin{enumerate}
	\item CCS: generate CCS from each sequencing ZMW
	\item Classify: identify full-length reads with primer removal
	\item Cluster: group reads derived from the same isoform to generate consensus sequence (high-quality full-length non-concatemer reads)	
\end{enumerate}
Bioinformatic analysis of Iso-Seq raw data can be performed using PacBio SMRT Link Suite (ref), a web-based end-to-end user interface. However, for optimisation of parameters and parallelisation of samples, an end-to-end command line was developed and used.  

\iffalse
\begin{figure}[h!]
	\centering
	\vspace{20pt}
	\includegraphics[width=0.8\linewidth, height=0.6\textheight]{Pictures/Isoseq_Pipeline.png}
	\captionsetup{width=0.95\textwidth}
	\caption[PacBio Isoseq Bioinformatics Pipeline]%
	{\textbf{PacBio Isoseq Bioinformatics Pipeline}: Pipeline is adapted from ToFU \nomenclature{ToFU}{Transcript isOforms: Full-length and Unassembled} \cite{Gordon2015}}
	\label{fig:isoseq_bioinformatics_Pipeline}
\end{figure}
\fi

Analysing long-read sequencing data requires a different approach to short-read, as the initial processing focuses on reducing the high error rate (due to low read coverage relative to short reads). Currently there were three methods of correcting long reads \cite{Zhao2019}: 
\begin{itemize}
	\item Hybrid error correction strategy using short-reads: LSC \cite{Au2012} which maps short reads, and LoRDEC which build De Brujin graph of short reads \cite{Salmela2014}
	\item Self-correction using long reads only: Long-read multiple aligner (LoRMA) \cite{Salmela2017}
	\item Reference-based correction by alignment of reads to reference genome by spliced-awwere aligners: Minimap2. GMAP and STAR can also be used for alignment, however, they do not perform error correction during alignment and further capture non-canonical splice sites.  
\end{itemize}

Although the raw error rate of PacBio sequencing is 10-14\%, this is greatly reduced by the use of circular template and subsequent generation of circular consensus sequence. 

\subsubsection{Classify}
\label{section:classify}

\uline{\textbf{CCS Generation}}: In the first stage, the raw subreads (stored as a BAM file, unaligned.bam) from each “productive” ZMW were processed individually and collapsed to generate a CCS (Figure \ref{fig:CCS}), according to: 
\begin{itemize}
	\item The number of full "passes" from the polymerase, and subsequently number of subreads generated; a full pass is defined by the presence of both SMRT adapters at both ends (Default: 3 passes)
	\item The minimum base accuracy across all subreads (Default: 99\%)
	\item Length of the subreads (Default: minimum 10 bases, maximum 21000 bases)
	\item Quality of Subread predicted by the CCS model (Default: Z-score of -3.5), and proportion of total subreads meeting the quality score (Default: \textgreater 30\%)
\end{itemize}

Across literature and PacBio scientific community, different parameter settings were recommended, particularly with \textit{number of full passes} and \textit{minimum base accuracy}, which had the greatest effect on the number of CCS reads generated for downstream analyses. Taking a subset of raw data from 10 randomised samples, a range of values across these two parameters were tested. CCS were then classified to full-length (FL, determined by the presence of 3'/5' primers and poly-A tail) and non-full-length (NFL) reads. 

\uline{\textbf{Lima}}: With successfully-generated CCS, cDNA primers and PacBio barcodes were identified and then removed using lima. CCS with unwanted orientations were removed and were oriented 5’ to 3’. A barcode score is calculated for each barcode pair (leading and trailing barcode), and is based on accuracy alignment to input cDNA primer sequences. The proportion of FL reads (number of FL reads over the number of CCS reads) varies on the insert transcript size; for Iso-Seq, a non-size selected library with a library distribution of 1-3kB typically has a 60-70\% FL. 

\uline{\textbf{Refine}}: Finally, full-length reads were refined by trimming of polyA tails, of a least a length of 20 bases, and removal of artificial concatemers to generate full-length non-chimeric (FLNC) reads. Artificial concatemers were defined as cDNA sequences with internal runs of polyA and polyT sequences, due to insufficient amount of blunt adapters during library preparation - this is typically rwere (<0.5\%). Conversely, it is challenging to differentiate and remove PCR-induced artificial chimera from true biological chimera. PCR-induced artefacts were defined as cDNA sequences that appear to be fusion transcripts, but were actually a result of non-optimal PCR reaction conditions. The number of FLNC reads should be very close to the number of FL reads, and any significant loss implicates issues at the SMRT bell library preparation.
Note Tama works on FLNC reads from Classify 

\subsubsection{Cluster}
In the second stage, Iso-Seq uses an iterative isoform-clustering algorithm (ICE – iterative clustering for error, called Quiver for PacBio RSII data and Arrow for PacBio Sequel data) to group all FLNC reads that were thought to be derived from the same isoform if: 
\begin{itemize}
	\item They differ less than 100bp on the 5’ end 
	\item Differ less 30bp on the 3’end 
	\item Do not contain internal gaps that exceed 10bp
\end{itemize}
By collapsing transcripts with differing 5' start [due to cDNA synthesis not preserving 5' end], some transcripts with alternative transcription start sites were lost while preserving those with alternative splicing and alternative polyadenylation. The representative transcript from those clustered is the longest one. 

A minimum of two FLNC reads were further required for a cluster. Consequently each FLNC read is classified to only one cluster, which is comprised of two or more FLNC reads. Two possible issues: reads belong to incorrect clusters, and reads that belong together were in separate clusters. [Briefly it first does clique-finding based on a similarity graph, then calls consensus using the Directed Acyclic Graph Consensus method and finally reassign sequences to different clusters based on their likelihood (Gordon et al. 2015)]. In previous Iso-Seq bioinformatic versions, NLF reads were used to increase the coverage of each consensus isoform. However, with increasing throughput with Sequel I and Sequel II, this has been foregone. Cluster outputs the high-quality isoforms (HQ-isoforms), which have a consensus accuracy >=99\%. 

So in summary, each productive ZMW generates one polymerase read, which is collapsed to give a circular consensus sequence (CCS) assuming the requirements were met. CCS were then trimmed and processed for primer and poly-A sequence removal to generate full-length non-chimeric (FLNC) reads, which were clustered if they were thought to be derived from the same isoform. The number of associated full-length (FL) reads of each isoform therefore represents the number of ZMWs that sequenced the isoform of interest, and can infer abundance of mRNA isoform. However, Iso-Seq is only semi-quantitative due to preferential loading and sequencing bias of shorter fragments. It is worthy to note that all the steps up to now have een processed without a reference genome or transcriptome. 


Iso-Seq Versions 
In response to a much higher experimental throughput of Sequel compwered to RSII, each subsequent   version of the official PacBio Iso-Seq tool saw a reduction in runtime, but an improvement of sensitivity to recover transcripts and specificity to reduce artefacts.

Iso-Seq 1 	
Iso-Seq 2	


In previous versions of official PacBio IsoSeq tool, non-FLNC reads were re-incorporated at this stage to polish the consensus isoforms. Short reads from RNA-Seq can also be incorporated for error correction using various tools such as LoRDEC, LSC and Proovread. 

Since the introduction of Iso-Seq protocol, 3 versions of the informatics pipeline has been developed. Iso-Seq2 has an extra pre-clustering step to bin full length non-chimeric reads based on gene families. The latest version Iso-Seq3 is used in response to the much higher throughput of Sequel compwered to RSII by using faster clustering algorithms. Using a more conservative primer removal and barcode demultiplexing step (with tool named LIMA), the Iso-Seq3 pipeline generates fewer but higher quality polished transcripts. 

High confidence transcripts can be determined by 1) presence of open reading frame (ORF), CDS length, interpro domain coverage, annotation edit distance 

\subsubsection{Genome/Transcriptome Alignment} 
High quality isoforms were then aligned to the reference genome (as opposed to transcriptome as otherwise miss novel isoforms using BLASR) using splice-awwere aligner Minimap2. Various long-read studies have used Minimap2 and GMAP (Križanovic et al. 2018 demonstrated marked success of GMAP vs other RNA-Seq Aligners). Tang et al. 2020, using subset of Oxford Nanopore reads evaluated number of splice sites mapped relative to known junctions, found Minimap2 to be more precise than GMAP. 

Using the –secondary=no parameter restricts the output to the best alignment, -x splice assumes read orientation relative to transcript strand unknown, and thus tries two rounds of alignment to infer orientation. As a splice-awwere alignment, -x splice prefers GT[A/G]…[C/T]AG over GT[C/T]…[A/G]AG over other splicing signals (main donor/acceptor motifs). –u f forces minimap2 to consider forward transcript strand only for alignment, slightly improving accuracy. –c 5 to accept non-canonical GT/AG splice junctions. 

--splice-flank=yes for human/mouse data in reads with relatively high sequencing error rate (necessary for ONT), but not for high quality IsoSeq reads (99\% - 100\%). 

\subsubsection{Genome Mapping}
HQ-isoforms from the pooled dataset were aligned to mouse genome using Minimap2, and a total of XXX reads (XX\%) were mapped. Errors for substitution, insertion and deletion were X\%, X\% and X\% respectively. XX\% of transcripts (polished) could not be mapped to reference genome, thus representing genes that fall into gaps in the assembly (mouse genome should be quite updated though)


\subsubsection{ERCC}
One source of error from long-read sequencing can occur at reverse transcription (RT)\nomenclature{RT}{Reverse Transcription}, whereby a premature termination in reverse transcription enzyme can result in a full-length cDNA, that is mistaken for a true isoform. To measure the degree of this technical error, ERCC, with known start and end positions can be used as benchmark. As detailed in \cite{Karlsson2017}, most ERCC reads fell within +/- 5bp at both 5' and 3' ends, with 3' end slightly more accurate than 5' end. From \cite{Sharon2013}, drop in read length was observed for ERCC for molecules longer than 1.5kb (PacBio RSII). Interestingly, non-coding exon junctions were more variable than coding-exon junctions, suggesting that codon exon splicing has a stricter control with refined splice donor/acceptor sites (\cite{Karlsson2017}) 
Of note, however, that while ERCC has been used as a standard for RNA-Seq method validation, the longest molecule is only ~2kB, thus limiting is usage to validate longer molecules. Given that XX of RNA transcripts in human and mouse transcriptome were >2kB, there is a need for longer control sequences. 

To assess the sensitivity across Iso-Seq runs to detect ERCC, a merged analysis of whole transcriptome samples (n = 10, WT = 5, TG = 5) was performed with ERCC alignment and further collapse using Cupcake. The counts of full-length transcripts pertaining to each sample were then obtained using a custom demultiplexed script, which classifies and counts the merged data based on the unique sequencing run id. Post SQANTI annotation and filtering, only a third of ERCCs (unique number of ERCC = 37, 40.22\%) were identified from both WT (mean number of ERCC: 32.4 (35\%)) and TG (mean number of ERCC: 32.2 (35.22\%)), with no difference in number of ERCC detected between WT and TG, although there were some ERCC that were detected in WT but not in TG, and vice versa. A minority of ERCCs (n = 8, 8.7\%) at higher concentration were further annotated with more than one "isoform", indicating the presence of technical artefacts and more stringent filtering or clustering required, with ERCC at a higher concentration more likely to be sequenced and annotated with multiple redundant "isoforms". Exploration of these "isoforms" revealed them to be shorter transcripts likely to be generated as a result of fragmentation of the original molecule, incomplete PCR synthesis and template-switching. Application of TAMA-GO's script, tama-remove-fragment-models.py, successfully removed these partial, redundant isoforms, while retaining the intact isoforms. 

Deeper investigation into the low coverage of ERCCs further identified an additional 20 lowly-expressed ERCCs that were discarded from cupcake's collapse scripts under the default coverage (alignment identity) parameters at 99\%. Exploration of these imperfect-aligned sequences revealed 5'prime degradation of XX-XX nucleotides - one of the limitations of not using a 5'cap protocol. Inclusion of these ERCCs using a lower minimum coverage threshold at 95\% increased the number of ERCCs detected by 20\% (unique number of ERCC = 57, 61.96\%), and strengthening the relationship between full-length read count and known amount of ERCC (95\% coverage: corr = 0.98, p = 1.41 x 10\textsuperscript{-41}; 99\% coverage: corr = 0.82, p = 4.89 x 10\textsuperscript{-10}).   


\subsubsection{Cupcake}
To avoid redundancy of transcripts, aligned and filtered HQ transcripts were further collapsed to obtain a final set of unique, full-length, high-quality isoforms using Cupcake (a set of publicly-available, supporting scripts). HQ transcripts were filtered out for lack of mapping and low coverage/identity before collapsing into unique isoforms.  

The abundance of each unique isoform can be estimated from the number of associated FL and NFL reads during IsoSeq cluster (not accounting for HQ transcripts that have been filtered out).  Finally, isoforms were filtered by 5’degradation due to the lack of a cap protection employed in the cDNA synthesis step (Clontech SMARTer cDNA kit). 

\subsubsection{Validation of isoforms with RNASeq} 
\label{section:ch2_rnaseq_support_bioinformatics}
Samples sequenced with paired-end reads, Illumina Hi-Seq, 125bases. Paired end reads as more accurate for identifying and sequencing junctions. RNASeq data through stringent filtering (plot of fastqc) and aligned to mouse genome (Gencode, version X) using STAR (see section X for parameters). Abundance in TPM was then calculated with Kallisto (v0.46.0) \cite{Bray2016} as an input into SQANTI to identify coverage of splicing junctions with RNASeq.  

Provides support of transcripts from RNA-Seq data, highest expression of RNA-Seq reads of the splice junctions 
The junction with lowest coverage from RNA-Seq, and its associated read count 	
Standard deviation of read counts across all the junctions for each transcript 


\subsubsection{SQANTI2 classification and filtering of isoforms} 
\label{sec:sq_exp}
High-quality, clustered, filtered isoforms from Cupcake were characterised using SQANTI2 (v7.4), a pipeline initially developed by Conesa et al. [ref] and refined by Elizabeth Tseng (Pacific Bioscience’s specialist) [ref].
In combination with genome annotation, SQANTI2 performs a reference-based correction of sequences and classifies isoforms based on splice junctions. The curated transcriptome can be further filtered and annotated with public datasets and RNA-Seq data (Section \ref{section:ch2_rnaseq_support_bioinformatics}). Public datasets include 
\begin{itemize}
	\item FANTOM5 Cap Analysis of Gene Expression (CAGE) peaks: map transcripts, transcription factors, transcriptional promoters and enhancers
	\item Intropolis\cite{Nellore2016} : a comprehensive human RNA-Seq dataset
	\item PolyA motifs 
\end{itemize}


\boldheader{Transcriptome Annotation and Isoform Classification}
\label{section: sqanti_annotations}
Using SQANTI classifications based on splice junctions, the transcriptome was segregated into the following categories (Figure \ref{fig:sqanti_cate}): 
\begin{itemize}
	\item Well-known annotated genes with known isoforms, further isoforms classified as
	\begin{itemize}
		\item Full Splice Match (FSM) if reference and query isoform have the same number of exons with matching internal junction. The 5’ and 3’ end, however, can differ 
		\item Incomplete Splice Match (ISM) if query isoform has fewer 5’ exons than the reference, but the 3’ exons and internal junctions match. The 5’ and 3’ ends can also differ 
	\end{itemize}
	\item Well-known annotated genes with novel isoforms, with isoforms classified as
	\begin{itemize}
		\item Novel in Catalog (NIC) if query isoform has different number and combination of exons to reference isoform, but is using a combination of known donor/acceptor splice sites 
		\item Novel Not In Catlog (NNC) if query isoform has different number and combination of exons to reference isoform like NNC, but also has at least one unannotated/novel donor or acceptor site
		\item Genic Intron: the query isoform is completely contained within an annotated intron.
		\item Genic Genomic: the query isoform overlaps with introns and exons.
	\end{itemize}
	\item Unannotated, novel genes with novel isoforms with isoforms classified as
	\begin{itemize}
		\item Antisense: the query isoform does not have overlap a same-strand reference gene but is anti-sense to an annotated gene.
		\item Intergenic: the query isoform is in the intergenic region
	\end{itemize}
\end{itemize}

Based on the pair of dinucleotides framing the intron boundary, splice junctions were either categorised as canonical for GT-AG, GC-AG and AT-AC and all the other possible combinations as non-canonical.  

Lastly it can provide further classification of transcripts:  
As protein-coding or non-protein-coding by the presence of coding sequence
that may potentially undergo non-sense medicated decay by the presence of ORF but CDS ends before the last junction
that contain one or multiple exons (mono-exonic or multi-exonic respectively)
that contain intronic sequences (intron retention) 
as fusions. The criteria XXXX

\iffalse
\begin{figure}[htp]
	\begin{center}
		\includegraphics[page=3,trim={2cm 28cm 2cm 5cm},clip,scale = 0.45]{Pipeline.pdf}
	\end{center}
	\captionsetup{width=0.95\textwidth}
	\caption[Isoform Classifications by SQANTI]%
	{\textbf{Isoforms were classified by SQANTI as novel or known, and annotated to novel or known genes based on splice junctions}. An isoform was classified as ‘FSM’ if it aligned with reference genome with the same splice junctions and contained the same number of exons, ‘ISM’ if it contained fewer 5’ exons than the reference genome, ‘NIC’ if it represented a novel isoform containing a combination of known donor or acceptor sites, or ‘NNC’ if it represented a novel isoform with at least one novel donor or acceptor site. FSM – Full splice match, ISM – Incomplete splice match, NIC – Novel in catalogue, NNC – novel not in catalogue}
	\label{fig:sqanti_cate}
\end{figure}
\fi

\boldheader{Further filtering of isoforms from technical artifacts}
SQANTI was further used to filter the curated transcriptome from any technical artifacts that were generated during library preparation, including artifacts from RT template switching (TS \nomenclature{TS}{Template Switching}) and off-priming \cite{Conesa2016} (Figure \ref{fig:lib_prep_artifacts}. RT template switching is an intrinsic feature of RT whereby the enzyme can transit within (intramolecular TS) or across (intermolecular TS) DNA templates without terminating cDNA synthesis, if the original DNA template harbours two or more direct repeats \cite{Cocquet2006}. This can result in either chimeric cDNAs or short, incomplete cDNAs that can be misinterpreted as isoforms generated from non-canonical splicing \cite{Houseley2010} (Figure \ref{fig:lib_prep_artifacts}a). Capitalising on the fact that RT switching is homology-dependent, SQANTI can identify these RT-switching artifacts by finding these direct repeats \cite{Conesa2016}. 

Finally, off-priming artifacts can be generated from the binding of oligo(dT) primer to other internal homopolymeric adenines (A) regions that can be located within cDNA template, and thereby generate truncated cDNAs \cite{Nam2002} (Figure \ref{fig:lib_prep_artifacts}b). SQANTI can explore the likelihood of thee events by determining the percentage of adenines (A) within the 20 nucleotide window downstream from the genomic coordinates of the isoform 3'ends and remove any that have a percentage lower than the user-defined threshold \cite{Conesa2016} - the lower the percentage of As, the higher the likelihood of the presence of internal polyA and off-priming. 

\begin{figure}[htp]
	\begin{center}
		\includegraphics[page=4,trim={2cm 35cm 0 1cm},clip, scale = 0.55]{Pipeline.pdf}
	\end{center}
	\captionsetup{width=0.95\textwidth}
	\caption[Technical artifacts generated during library preparation and identified in SQANTI]%
	{\textbf{SQANTI identifies technical artifacts that were generated during first-strand cDNA synthesis a)}: Schematic diagram of reverse transcription template switching, taken from Cocquet et al.(2006) \cite{Cocquet2006}. The black and blue line represent the original cDNA and synthesising cDNA from RT respectively, the black box represent the direct repeats and the light grey sphere represent the RT enzyme. As exemplified, RT template switching is further facilitated by RNA secondary structures that could bring the repeats into proximity \cite{Cocquet2006}. \textbf{b)} Schematic diagram of off-priming of oligo(dT) primer to internal A repeats, taken from Nam et al. (2002) \cite{Nam2002}. Oligo(dT) primer from first-strand cDNA synthesis can anneal to internal poly(A) sequence rather than the 3'end polyA, resulting in two truncated cDNAs.}
	\label{fig:lib_prep_artifacts}
\end{figure}
 
%This was developed to remove artifacts from library preparation: i.e. intrapriming of polyA that usually happens in antisense strands and also lack of junction support in NNC; increase \% of FSM transcripts, and removes NIC. 

In summary, the isoforms were filtered by the following criteria: 
\begin{enumerate}
	\item FSM with a reliable 3’ end by:
	\begin{itemize}
		\item >60\% of As in transcription termination site and no detected polyA motif, indicative of genomic contamination
		\item <Xbp 5' start and 3’ end to reference transcript start end
	\end{itemize}
	\item Any other transcripts that have a reliable 3' end do not have any splice junctions were annotated as Reverse Transcription Switching. 
\end{enumerate}

\subsubsection{Isoform Quantification}
Isoform abundance was determined in two ways, using either a hybrid approach of long and short reads or the normalised full-length long read count as proxy (\cref{fig:isoform_quant_strategy}). The hybrid approach was a modified strategy of typical RNA-Seq quantiative analyses, whereby short reads were aligned to the Iso-Seq defined transcriptome (a merged, comprehensive annotation) rather than the reference genome, thereby improving read alignment to condition-specific transcripts and enabling the detection of novel transcripts. 


\begin{figure}[htp]
	\begin{center}
		\includegraphics[page=8,trim={2cm 32cm 0 1cm},clip, scale = 0.4]{Pipeline.pdf}
	\end{center}
	\captionsetup{width=0.95\textwidth}
	\caption[Strategies for isoform quantification]%
	{\textbf{Strategies for isoform quantification using long and short reads}: A schematic diagram of three strategies adopted for determining isoform abundance, using either short RNA-Seq reads aligned to the reference genome or the Iso-Seq defined transcriptome (hybrid approach), or the normalilsed full-length read count directly from long reads}
	\label{fig:isoform_quant_strategy}
\end{figure}


\boldheader{Removal of ISM and merging of FSMs}
Following \textit{SQANTI} annotations, there were many examples where multiple ISMs and several FSM transcripts were annotated to the same known isoform (exemplified in \cref{fig:redudant_sncatranscripts}). This is likely due to varying extent of 5'degradation and truncation - small degree of degradation or truncation would result in differing 5' and 3' ends respectively while preserving the internal exonic structure and thereby generating several FSMs; conversely, a large degree of degradation or truncation would generate smaller partial isoforms that also have matching, albeit smaller overlap, exonic structure. To ease downstream quantitative analyses, ISMs and shorter FSMs were assumed as partial products of the longest detected FSM transcript, and the associated counts were aggregated (as shown in \cref{fig:ism_collapse}). However, there is a caveat that significantly shorter ISM transcripts could in theory be mapped to multiple isoforms.  

\begin{figure}[htp]
	\begin{center}
		\includegraphics[page=10,trim={0cm 0cm 0 0cm},clip, scale = 0.45]{Pipeline.pdf}
	\end{center}
	\captionsetup{width=0.95\textwidth}
	\caption[Redundant ISMs and FSMs associated with same known isoform]%
	{\textbf{Redundant ISMs and FSMS associated with known transcript of \textit{Snca}}: \textbf{a)} Visualisig transcripts using \textit{Swan}, shown are \textbf{b)} transcripts detected after \textit{SQANTI} annotation of the mouse transcriptome using the targeted approach. An example of detecting multiple redundant transcripts annotated to the same isoform, all the transcripts depicted were annotated to ENMUST0000014268.4 which typically differed at the 5' and 3' end.}
	\label{fig:redudant_sncatranscripts}
\end{figure}

\begin{figure}[htp]
	\centering
	\includegraphics[page=9,trim={0cm 21cm 0cm 0cm},clip,scale = 0.45]{Pipeline.pdf}
	\captionsetup{width=0.95\textwidth,singlelinecheck=off}
	\caption[Merging of ISMs and FSMs]%
	{\textbf{Merging of ISMs and FSMs associated with the same known isoform}. All illustration of handling with multiple ISM and FSM associated with the same known transcript. In this example, 6 isoforms were detected for "Gene 1", however, only 4 known isoforms were identified (denoted as ENMUST1-4). For ease of annotation and quantification, ISMs and shorter FSMs were assumed partial products of the longer FSM. Consequently, in the case where: 
		\begin{itemize}
			\item both ISM (PB.1.2) and FSM (PB.1.1) are annotated to the same transcript (shaded green), the FSM takes precedence as the associated transcript and counts from respective ISMs are aggreated 
			\item there is one ISM (PB.1.3) but no corresponding FSMs for the associated transcript (shaded blue), the ISM is retained
			\item there are multiple ISMs (PB.1.4, PB.1.5) annotated to the same transcript (shaded orange), the longest ISMs (PB.1.5) takes precedence and counts from respective ISMs are similarly aggregated 
			\item there are multiple FSMs (PB.1.6, PB.1.7) annotated to the same transcript (shaded purple), the longest FSM (PB.1.7) takes precedence and counts are similarly aggreagated
			\\
		\end{itemize} 
		PB - PacBio. FSM - Full Splice Match, ISM - Incomplete Splice Match, FL - Full-length read counts.  
	}
	\label{fig:ism_collapse}
\end{figure}

\boldheader{RNA-Seq Alignment to Iso-Seq defined transcriptome}
For the hybrid approach of aligning short reads to Iso-Seq defined trascriptome from the targeted approach, several factors were optimised including the library size and the Iso-Seq annotation (\cref{tab:rnaseq_alignment_targeted}). 

\begin{table}[!h]
	\centering
	\caption[RNA-Seq Alignment strategy to Iso-Seq defined targeted transcriptome]%
	{\textbf{RNA-Seq Alignment strategy to Iso-Seq defined targeted transcriptome}. Tabulated is trialled methods of aligning short reasd to Iso-Seq defined transcriptome, with alterations either of the sequencing library (such as the pool of the sequencing reads for alignment) and the choice of Iso-Seq isoform for alignment}
	\label{tab:rnaseq_alignment_targeted}
	\begin{threeparttable}
	\begin{tabular}{@{}cll@{}}
		\toprule
		Method & Sequencing Library                       & Annotation                            \\ \midrule
		1      & Targeted Transcriptome (All Reads)\tnote{a}       & No Isoform collapse\tnote{c}                   \\
		2      & Targeted Transcriptome (All Reads)\tnote{a}       & Isoform collapse to longest FSM\tnote{d}       \\
		3      & Targeted Transcriptome (All Reads)\tnote{a}       & Isoform collapse to most abundant FSM\tnote{e} \\
		4      & Targeted Transcriptome (On Target Reads)\tnote{b} & Isoform collapse to longest FSM\tnote{d}       \\
		5      & Targeted Transcriptome (On Target Reads)\tnote{b} & Isoform collapse to most abundant FSM\tnote{e} \\
		6 & \begin{tabular}[c]{@{}l@{}}Whole Transcriptome \& \\ Targeted Transcriptome (On Target Reads)\end{tabular} & Isoform collapse to longest FSM \\ \bottomrule
	\end{tabular}
	\begin{tablenotes}
		\footnotesize
		\item[a] Sequencing reads from on-target and off-target genes
		\item[b] Sequencing reads aligned only to target genes
		\item[c] Transcriptome annotation following \textit{SQANTI} with no removal of redundant ISMs and FSMs
		\item[d] Transcriptome annotation following \textit{SQANTI} with collapse of redundant ISMs to respective longest FSM of same transcript and aggregated counts
		\item[e] Transcriptome annotation following \textit{SQANTI} with collapse of redundant ISMs to respective most abundant FSM of same transcript and aggregated counts 
	\end{tablenotes}
	\end{threeparttable}
\end{table}

- Noticed different output dependent on the choice of Iso-Seq isoforms for alignment and the sequencing library, with either different quantification pattern or annotation of differentially expressed isoform to differet isoform to that ascribed using Iso-Seq reads (often novel isoforms)

\begin{landscape}
\begin{figure}[htp]
	\centering
	\includegraphics[page=1,trim={0cm 0cm 0cm 0cm},clip,scale = 0.8]{ProjectDevelopment_Figures_Landscape}
	\captionsetup{width=0.95\textwidth,singlelinecheck=off}
	\caption[Merging of ISMs and FSMs]%
	{\textbf{Merging of ISMs and FSMs associated with the same known isoform}. 
	}
	\label{fig:ism_collapse}
\end{figure}

\begin{figure}[htp]
	\centering
	\includegraphics[page=2,trim={0cm 0cm 0cm 0cm},clip,scale = 0.8]{ProjectDevelopment_Figures_Landscape}
	\captionsetup{width=0.95\textwidth,singlelinecheck=off}
	\caption[Merging of ISMs and FSMs]%
	{\textbf{Merging of ISMs and FSMs associated with the same known isoform}. 
	}
	\label{fig:ism_collapse}
\end{figure}
\end{landscape}

\subsubsection{Iso-Seq isoform expression}
To control for sequencing bias in library depth, full-length (FL) read count for each isoform is normalized to transcripts per million (TPM \nomenclature{TPM}{Transcripts per Million})), which is calculated as: 

\begin{align*}
FL\;\:TPM (x_{sample},y_{sample})=\frac{Raw\;\:FL\;\:count (x_{isoform},y_{sample})}{Total\;\:FL\;\:count (y_{sample})} *10^6
\end{align*}

With a cut-off lower than 0.5 TPM, a 0.5 - 10 TPM refers to low expression, a 11- 1000 refers to medium expression, and > 1000 TPM high expression [literature ref]. 

TPM is the most effective within-sample normalisation method to relatively quantify gene expression in a sample \cite{Abrams2019}. Other methods include RPKM (reads per kilobase of transcripts per million mapped reads), FPKM (fragments per kilobase of exon model per million mapped reads), which uses gene length to control for fragmentation in RNA-Seq protocol ("effective length normalisation") - however, this is not necessary in Iso-Seq.  

Between-sample normalisation methods to relatively quantify expression of the same gene in different samples, remove technical variations due to presence of few highly expressed genes that make up a significant proportion of total reads, and due to different number of reads in each sample. 

\subsubsection{Limitations}
While PacBio's Iso-Seq have major potential for transcriptome annotation, there were currently several major limitations that need to be addressed with further development of library preparation and bioinformatic data analyses \cite{Kuo2017}: 
\begin{enumerate}
	\item Lack of normalisation of RNA libraries, resulting in biased sequencing of high abundance transcripts and subsequent over-representation of such transcripts 
	\item Degradation of transcripts from 5' end, and thus lack of confidence in transcription start site and full-length structure 
\end{enumerate}

Despite the ability of long-read sequencing (particularly, Iso-Seq\nomenclature{Iso-Seq}{Isoform Sequencing}) to discover large number of novel and longer transcripts and identify complex splicing events such as alternative adenylation, there are inherent biases to sequencing the more highly-expressed and relatively shorter transcripts. Consequently, while the new chemistry has improved the error rate and increased throughput, the coverage is still insufficient for accurate transcript quantification and sensitive differential transcript analysis based on long reads alone (Koren et al., 2012). Furthermore, there is currently no consensus to validate or functionally characterise these transcripts (B. Wang, Kumar, Olson, \& Ware, 2019). The current standard for such application is thus a hybrid approach of aligning the short-reads to the long-reads to improve alignment and assemblage, and for downstream isoform quantification. 

Isoform-specific expression can be deduced from short-reads alone using statistical models if the gene is well annotated (i.e. all isoforms are known) based on i) reads aligning to contiguous genomic segment (exonic reads) and ii) reads aligning to two contiguous segments with a single gap of 60-400bp (junction reads)(Jiang and Wong, 2009)).

Various bioinformatic tools and computational models have been developed to quantify isoform quantification from RNA-Seq data. There are currently two main methods:
\begin{enumerate}
	\item Inclusion level, calculated for a regulated exon by aligning reads either to candidate alternative exons and its junctions (inclusion reads), or to flanking exons and subsequently skipping the candidate alternative exon (skipping/exclusion reads) (Chen et al. 2012)
	\item Percent-Spliced-In (PSI\nomenclature{PSI}{Percent-Spliced In}), calculated by proportion of isoforms that include the exon (Venables et al. 2008)(Katz et al. 2010). If the PSI value is calculated for a particular splicing event, it can be considered equivalent to the inclusion level. 
\end{enumerate}
Isoform quantification can either be expressed as a global measure of expression, which provides a global gene expression ranking in one sample (measured by RPKM: Reads of a transcript sequence per Millions mapped read\nomenclature{RPKM}{Reads of a transcript sequence per Millions}), or as a relative measure of expression, which is normalized per gene locus and comparable across conditions (measured by inclusion level or PSI value). 

Isoform abundance calculated by aligning short-reads to transcriptome is preferential to alignment with reference annotation library (RefSeq/GENCODE) in narrowing down the isoforms expressed and thus subsequently enabling more reliable abundance quantification. Reference annotation library is constructed on all data from the same species, and inclusion of annotated but not truly expressed isoforms can increase variability of abundance estimates. Finally, if the reference library is incomplete, then truly expressed isoforms would be completely missed and RNA-Seq reads would be incorrectly assigned to annotated isoform (\cite Au2013)


\textbf{Differential Isoform Usage }\\
\label{intro:dtu}
When analyzing splicing patterns between multiple conditions, changes in isoform abundance can be defined in two ways: 
\begin{enumerate}
	\item Differential Isoform Expression (DIE\nomenclature{DIE}{Differential Isoform Expression}): changes in absolute expression of an isoform, evaluated using count matrixes 
	\item Differential Isoform Usage (DIU\nomenclature{DIU}{Differential Isoform Usage}): changes in relative expression of an isoform from the same gene, resulting in a change in isoform proportion and is evaluated using changes in gene exon usage	
\end{enumerate}

Figure X shows an example of a change in DIE but no change in DS: A two-fold increase of both isoforms from the same gene results in a change in absolute but not relative expression to one another. A change in DIE but not in DS may indicate a transcription-related mechanism. If a change in DS is observed, a change in DIE of one of the isoforms would also be observed. A change in multiple isoforms would also be observed, as long as the change is not in the same direction (upregulated/downregulated) with the same magnitude. Any changes in DS/relative abundance of isoforms indicate a splicing-related mechanism. 

In addition to exploring differential splicing in terms of isoform abundance, which typically involves an exon-based approach that focuses on differential exon usage (i.e. DEXSeq), a splicing based approach can also be taken. This involves analyzing individual splicing events (exon skipping, alternative donor and acceptor) for systematic changes between conditions. rMATS, SUPP2, LeafCutter and Majiq are such tools that identify and quantify splicing events using junction reads. 

	 